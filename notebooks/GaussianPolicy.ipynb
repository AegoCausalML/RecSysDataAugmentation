{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c78b22",
   "metadata": {},
   "source": [
    "# Politica Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e884b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def normal(x, mu, sigma_sq):\n",
    "    a = (-1*(x-mu).pow(2)/(2*sigma_sq)).exp()\n",
    "    b = 1/(2*sigma_sq*math.pi).sqrt()\n",
    "    return a*b\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, n_users: int, d_R: int, hidden_dimension: int):\n",
    "        '''\n",
    "        Params:\n",
    "            - n_users: número de usuários\n",
    "            - d_R: dimensão da representação dos usuários\n",
    "            - hidden_dimension: número de neurôneos na camada oculta\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_users = n_users\n",
    "        self.d_R = d_R\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "\n",
    "        self.one_hot = F.one_hot\n",
    "        \n",
    "        self.linear1 = nn.Linear(n_users, hidden_dimension)\n",
    "        self.linear_mu = nn.Linear(hidden_dimension, d_R)\n",
    "        self.linear_sigma = nn.Linear(hidden_dimension, d_R)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = self.one_hot(xb, num_classes=self.n_users).to(torch.float32)\n",
    "        xb = F.relu(self.linear1(xb))\n",
    "        mu = self.linear_mu(xb)\n",
    "        sigma_sq = self.linear_sigma(xb)\n",
    "        return mu, sigma_sq\n",
    "    \n",
    "    def act(self, xb):\n",
    "        # Batch of users\n",
    "        mu, sigma_sq = self.forward(xb)\n",
    "        sigma_sq = F.softplus(sigma_sq)\n",
    "        eps = torch.randn(mu.size())\n",
    "        action = (mu + sigma_sq.sqrt()*eps).data\n",
    "        log_prob = normal(action, mu, sigma_sq).log()\n",
    "        return action, log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "# distrib = MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "# distrib.rsample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d339ab7",
   "metadata": {},
   "source": [
    "# CPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a870322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from src.pr_model import P_R_Network\n",
    "from src.ps_model import P_S_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "32d01887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPR:\n",
    "    def __init__(self, pr_model, ps_model, n_items):\n",
    "        self.pr_model = pr_model\n",
    "        self.Q = pr_model.item_emb.weight.data\n",
    "        self.wR = pr_model.w.data.squeeze()\n",
    "        \n",
    "        self.ps_model = ps_model\n",
    "        self.n_items = n_items\n",
    "    \n",
    "    def sample_alpha_posterior(self):\n",
    "        return torch.randn(self.n_items)\n",
    "    \n",
    "    def sample_beta_posterior(self, k):\n",
    "        return torch.randn(k)\n",
    "    \n",
    "    def gen_r_from_tau(self, tau, k):\n",
    "        \"\"\"\n",
    "        tau: action center - torch.tensor(1, emb_dim)\n",
    "        k: number of items - int\n",
    "        \"\"\"\n",
    "        alpha = self.sample_alpha_posterior()\n",
    "        score = (tau @ self.Q.T) + (self.wR * alpha)\n",
    "        scores_dict = dict(enumerate(score))\n",
    "        sorted_dict = dict(sorted(scores_dict.items(), key=lambda item:item[1], reverse=True))\n",
    "        return list(sorted_dict.keys())[:k]\n",
    "    \n",
    "    def gen_s(self, u, r, M):\n",
    "        \"\"\"\n",
    "        u: user id - int\n",
    "        r: list of item ids - [int]\n",
    "        M - itens to be selected - int\n",
    "        \"\"\"\n",
    "        beta = self.sample_beta_posterior(len(r))\n",
    "        \n",
    "        u_b = torch.LongTensor([[u]])\n",
    "        r_b = torch.LongTensor([r])\n",
    "        r_mask_b = torch.ones(1, len(r))\n",
    "        beta_b = beta.unsqueeze(0)\n",
    "        score = self.ps_model(u_b, r_b, r_mask_b, None, beta_b).data[0]\n",
    "        \n",
    "        scores_dict = dict(zip(r, score))\n",
    "        sorted_dict = dict(sorted(scores_dict.items(), key=lambda item:item[1], reverse=True))\n",
    "        return list(sorted_dict.keys())[:M]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe35e0f",
   "metadata": {},
   "source": [
    "# Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d75ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'MIND-small_pp'\n",
    "user_df = pd.read_csv(join(data_path, 'user_d.csv'))\n",
    "user_d = {code: ind for code, ind in zip(user_df['code'], user_df['indice'])}\n",
    "item_df = pd.read_csv(join(data_path, 'item_d.csv'))\n",
    "item_d = {code: ind for code, ind in zip(item_df['code'], item_df['indice'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6b8455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model = P_R_Network(len(user_d)+1, len(item_d)+1)\n",
    "pr_model.load_state_dict(torch.load('pr_model_60epochs/pr_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ca35bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_model = P_S_Network(len(user_d)+1, len(item_d)+1, 299)\n",
    "ps_model.load_state_dict(torch.load('ps_model_100epochs/ps_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4fd7fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpr = CPR(pr_model, ps_model, len(item_d)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aee16",
   "metadata": {},
   "source": [
    "# Treinar Gaussiana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01b95aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPR_Env:\n",
    "    def __init__(self, cpr, recommender, k, M):\n",
    "        self.cpr = cpr\n",
    "        self.recommender = recommender\n",
    "        self.k = k\n",
    "        self.M = M\n",
    "        \n",
    "    def compute_reward(self, action, u):\n",
    "        \"\"\"\n",
    "        Recebe um batch de acoes e devolve um batch de recompensas\n",
    "        action: torch.tensor(batch_sz, emb_dim)\n",
    "        u: torch.tensor(batch_sz)\n",
    "        reward: torch.tensor(batch_sz)\n",
    "        \"\"\"\n",
    "        batch_sz = action.size(0)\n",
    "        reward = torch.zeros(batch_sz)\n",
    "        for i in range(batch_sz):\n",
    "            u_id = u[i].item()\n",
    "            tau = action[i].unsqueeze(0)\n",
    "            r = self.cpr.gen_r_from_tau(tau, self.k)\n",
    "            s = self.cpr.gen_s(u_id, r, self.M)\n",
    "            reward[i] = self.recommender.calculate_loss(u_id, r, s)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8fe8fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_batch(policy, optimizer, u, env):\n",
    "    action, log_prob = policy.act(u)\n",
    "    reward = env.compute_reward(action, u)\n",
    "    loss = -(log_prob * reward.unsqueeze(1)).sum() #Ideia: torch.ones(3,4) * torch.tensor([1,2,3]).unsqueeze(1)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "04141337",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CPR_Env(cpr, None, 5, 2) # alterar para colocar o recomendador para calcular loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1d3654d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = GaussianPolicy(len(user_d)+1, 32, 16)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a4d9486b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'calculate_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2y/kyv2hdc1433f67fbbd7zm9zr0000gn/T/ipykernel_47667/2985651887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreinforce_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2y/kyv2hdc1433f67fbbd7zm9zr0000gn/T/ipykernel_47667/3988061953.py\u001b[0m in \u001b[0;36mreinforce_batch\u001b[0;34m(policy, optimizer, u, env)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreinforce_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Ideia: torch.ones(3,4) * torch.tensor([1,2,3]).unsqueeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2y/kyv2hdc1433f67fbbd7zm9zr0000gn/T/ipykernel_47667/3770239674.py\u001b[0m in \u001b[0;36mcompute_reward\u001b[0;34m(self, action, u)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_r_from_tau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'calculate_loss'"
     ]
    }
   ],
   "source": [
    "# Loop de treinamento => tem que corrgir para colocar a loss do recomendador\n",
    "for ep_i in range(100):\n",
    "    u = torch.randint(1, len(user_d)+1, (batch_size,))\n",
    "    reinforce_batch(policy, optimizer, u, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "51bb7432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04866621614947534"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "202003 /4150785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ecf96015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.54813542373133"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4150785 / 202003 #20.54813542373133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ac703ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.352"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*0.011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4da24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
