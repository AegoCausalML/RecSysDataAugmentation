{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tT7wkV2O1KZL",
    "outputId": "d71f3007-5a7b-49e4-b094-c612c71993c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting recommenders\n",
      "  Downloading recommenders-1.1.1-py3-none-any.whl (339 kB)\n",
      "\u001b[K     |████████████████████████████████| 339 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk<4,>=3.4\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (1.21.4)\n",
      "Collecting transformers<5,>=2.5.0\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<6,>=5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-macosx_10_9_x86_64.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 47.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: seaborn<1,>=0.8.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (0.11.2)\n",
      "Collecting scikit-surprise>=1.0.6\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "\u001b[K     |████████████████████████████████| 771 kB 22.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cornac<2,>=1.1.2\n",
      "  Downloading cornac-1.14.2-cp38-cp38-macosx_10_14_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 116 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.31.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (4.64.0)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (1.7.3)\n",
      "Collecting pandera[strategies]>=0.6.5\n",
      "  Downloading pandera-0.13.4-py3-none-any.whl (122 kB)\n",
      "\u001b[K     |████████████████████████████████| 122 kB 31.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightfm<2,>=1.15\n",
      "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
      "\u001b[K     |████████████████████████████████| 310 kB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2<3.1,>=2 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (3.0.3)\n",
      "Requirement already satisfied: matplotlib<4,>=2.2.2 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (3.5.1)\n",
      "Collecting numba<1,>=0.38.1\n",
      "  Downloading numba-0.56.4-cp38-cp38-macosx_10_14_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 58.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightgbm>=2.2.1\n",
      "  Downloading lightgbm-3.3.3-py3-none-macosx_10_15_x86_64.macosx_11_6_x86_64.macosx_12_0_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting category-encoders<2,>=1.3.0\n",
      "  Downloading category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.0.3,>=0.22.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (1.0.2)\n",
      "Requirement already satisfied: pandas<2,>1.0.3 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (1.4.3)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from recommenders) (2.28.1)\n",
      "Collecting bottleneck<2,>=1.2.1\n",
      "  Downloading Bottleneck-1.3.5-cp38-cp38-macosx_10_9_x86_64.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 26.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting memory-profiler<1,>=0.54.0\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Collecting statsmodels>=0.6.1\n",
      "  Downloading statsmodels-0.13.5-cp38-cp38-macosx_10_9_x86_64.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 70.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.4.1\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting powerlaw\n",
      "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from jinja2<3.1,>=2->recommenders) (2.0.1)\n",
      "Requirement already satisfied: wheel in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from lightgbm>=2.2.1->recommenders) (0.37.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from matplotlib<4,>=2.2.2->recommenders) (4.28.5)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.4-cp36-abi3-macosx_10_9_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 26.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from nltk<4,>=3.4->recommenders) (1.1.0)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.10.31-cp38-cp38-macosx_10_9_x86_64.whl (294 kB)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-macosx_10_9_x86_64.whl (25.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.5 MB 70.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from numba<1,>=0.38.1->recommenders) (58.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from numba<1,>=0.38.1->recommenders) (4.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from pandas<2,>1.0.3->recommenders) (2022.1)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-inspect>=0.6.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting hypothesis>=5.41.1\n",
      "  Downloading hypothesis-6.60.0-py3-none-any.whl (398 kB)\n",
      "\u001b[K     |████████████████████████████████| 398 kB 57.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from hypothesis>=5.41.1->pandera[strategies]>=0.6.5->recommenders) (21.2.0)\n",
      "Collecting sortedcontainers<3.0.0,>=2.1.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting exceptiongroup>=1.0.0\n",
      "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from patsy>=0.4.1->category-encoders<2,>=1.3.0->recommenders) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from requests<3,>=2.0.0->recommenders) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from requests<3,>=2.0.0->recommenders) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from requests<3,>=2.0.0->recommenders) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from requests<3,>=2.0.0->recommenders) (3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from scikit-learn<1.0.3,>=0.22.1->recommenders) (3.0.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 62.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers<5,>=2.5.0->recommenders) (4.0.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages (from importlib-metadata->numba<1,>=0.38.1->recommenders) (3.6.0)\n",
      "Collecting mpmath\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[K     |████████████████████████████████| 532 kB 36.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: lightfm, scikit-surprise\n",
      "  Building wheel for lightfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightfm: filename=lightfm-1.16-cp38-cp38-macosx_10_9_x86_64.whl size=446310 sha256=03910d0f07dbba4f5ec2e50083a1fd24014c13d4f0e5fe2fbc061df629215332\n",
      "  Stored in directory: /Users/zeba/Library/Caches/pip/wheels/ec/bb/51/9c487d021c1373b691d13cadca0b65b6852627b1f3f43550fa\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-macosx_10_9_x86_64.whl size=1180300 sha256=850ff5ee74a293a874f797ab14e0d26b62f70e76b9b25080fe9015540ce4f53d\n",
      "  Stored in directory: /Users/zeba/Library/Caches/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
      "Successfully built lightfm scikit-surprise\n",
      "Installing collected packages: typing-extensions, mypy-extensions, wrapt, typing-inspect, sortedcontainers, pyyaml, pydantic, patsy, mpmath, filelock, exceptiongroup, tokenizers, statsmodels, regex, psutil, powerlaw, pandera, llvmlite, hypothesis, huggingface-hub, click, transformers, scikit-surprise, retrying, numba, nltk, memory-profiler, lightgbm, lightfm, cornac, category-encoders, bottleneck, recommenders\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.0\n",
      "    Uninstalling typing-extensions-4.0.0:\n",
      "      Successfully uninstalled typing-extensions-4.0.0\n",
      "Successfully installed bottleneck-1.3.5 category-encoders-1.3.0 click-8.1.3 cornac-1.14.2 exceptiongroup-1.0.4 filelock-3.8.2 huggingface-hub-0.11.1 hypothesis-6.60.0 lightfm-1.16 lightgbm-3.3.3 llvmlite-0.39.1 memory-profiler-0.61.0 mpmath-1.2.1 mypy-extensions-0.4.3 nltk-3.7 numba-0.56.4 pandera-0.13.4 patsy-0.5.3 powerlaw-1.5 psutil-5.9.4 pydantic-1.10.2 pyyaml-5.4.1 recommenders-1.1.1 regex-2022.10.31 retrying-1.3.4 scikit-surprise-1.1.3 sortedcontainers-2.4.0 statsmodels-0.13.5 tokenizers-0.13.2 transformers-4.25.1 typing-extensions-4.4.0 typing-inspect-0.8.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LqVXO52J3kKe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eDw4wtRv8v5z"
   },
   "outputs": [],
   "source": [
    "MIND_VERSION = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bqUuFTLa6Oom"
   },
   "outputs": [],
   "source": [
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCbeZO6c7Gzx",
    "outputId": "a9c56d70-949f-4742-8457-b991c50ca24d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 17.0k/17.0k [00:10<00:00, 1.67kKB/s]\n",
      "100%|█████████████████████████████████████| 9.84k/9.84k [00:03<00:00, 2.65kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M-vfEiWo9yvP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "behaviors_col_names = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "train_data = pd.read_table(train_behaviors_file, header=None, names=behaviors_col_names)\n",
    "valid_data = pd.read_table(valid_behaviors_file, header=None, names=behaviors_col_names)\n",
    "\n",
    "def data_to_recommended_and_selected(dataframe: pd.DataFrame, user_col: str = 'UserID', interactions_col: str = 'Impressions'):\n",
    "    data = list()\n",
    "    items = set()\n",
    "    for user, user_interactions in zip(dataframe[user_col].values, dataframe[interactions_col].values):\n",
    "        \n",
    "        # Interações são da forma noticia_id-clicado, exemplo: N23699-0 N21291-0 N1901-1 N27292-0 N17443-0\n",
    "\n",
    "        R = [interaction.split('-')[0] for interaction in user_interactions.split()] \n",
    "        S = [interaction.split('-')[0] for interaction in user_interactions.split() if interaction[-1] == '1']\n",
    "        \n",
    "        items.update(R)\n",
    "\n",
    "        data.append((user, ' '.join(R), ' '.join(S)))\n",
    "\n",
    "    return pd.DataFrame(data, columns=['UserID', 'R', 'S']), items\n",
    "\n",
    "train_data, train_items = data_to_recommended_and_selected(train_data)\n",
    "valid_data, valid_items = data_to_recommended_and_selected(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "t09cL0DkCdsP",
    "outputId": "e2d04188-7325-4d80-a7c7-58b36a25da58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U82271</td>\n",
       "      <td>N13390 N7180 N20785 N6937 N15776 N25810 N20820...</td>\n",
       "      <td>N15368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U84185</td>\n",
       "      <td>N13089 N18101 N1248 N26273 N12770 N1132 N13649</td>\n",
       "      <td>N12770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U11552</td>\n",
       "      <td>N18390 N10537 N23967</td>\n",
       "      <td>N23967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U68381</td>\n",
       "      <td>N15660 N18609 N2831 N5677 N19010 N1502 N19215 ...</td>\n",
       "      <td>N18390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U52303</td>\n",
       "      <td>N15645 N7911</td>\n",
       "      <td>N7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22029</th>\n",
       "      <td>U69508</td>\n",
       "      <td>N16297 N15645 N20630 N10602 N27294 N24649 N129...</td>\n",
       "      <td>N9916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22030</th>\n",
       "      <td>U79085</td>\n",
       "      <td>N27355 N9809 N20882 N8787 N25926 N3864 N15163 ...</td>\n",
       "      <td>N13282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22031</th>\n",
       "      <td>U46989</td>\n",
       "      <td>N13316 N23592 N10240 N1994 N26998 N17157 N1324...</td>\n",
       "      <td>N13247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22032</th>\n",
       "      <td>U49050</td>\n",
       "      <td>N23982 N17424 N17157 N4324 N22216 N14332 N6221...</td>\n",
       "      <td>N13557 N7050 N18892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22033</th>\n",
       "      <td>U6774</td>\n",
       "      <td>N5109 N7452 N13064 N26428 N22785 N23921 N27197...</td>\n",
       "      <td>N4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22034 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserID                                                  R  \\\n",
       "0      U82271  N13390 N7180 N20785 N6937 N15776 N25810 N20820...   \n",
       "1      U84185     N13089 N18101 N1248 N26273 N12770 N1132 N13649   \n",
       "2      U11552                               N18390 N10537 N23967   \n",
       "3      U68381  N15660 N18609 N2831 N5677 N19010 N1502 N19215 ...   \n",
       "4      U52303                                       N15645 N7911   \n",
       "...       ...                                                ...   \n",
       "22029  U69508  N16297 N15645 N20630 N10602 N27294 N24649 N129...   \n",
       "22030  U79085  N27355 N9809 N20882 N8787 N25926 N3864 N15163 ...   \n",
       "22031  U46989  N13316 N23592 N10240 N1994 N26998 N17157 N1324...   \n",
       "22032  U49050  N23982 N17424 N17157 N4324 N22216 N14332 N6221...   \n",
       "22033   U6774  N5109 N7452 N13064 N26428 N22785 N23921 N27197...   \n",
       "\n",
       "                         S  \n",
       "0                   N15368  \n",
       "1                   N12770  \n",
       "2                   N23967  \n",
       "3                   N18390  \n",
       "4                    N7911  \n",
       "...                    ...  \n",
       "22029                N9916  \n",
       "22030               N13282  \n",
       "22031               N13247  \n",
       "22032  N13557 N7050 N18892  \n",
       "22033                N4326  \n",
       "\n",
       "[22034 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIND Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../MIND-small'\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "\n",
    "valid_news_file = os.path.join(data_path, 'dev', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'dev', r'behaviors.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_col_names = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "train_data = pd.read_table(train_behaviors_file, header=None, names=behaviors_col_names)\n",
    "valid_data = pd.read_table(valid_behaviors_file, header=None, names=behaviors_col_names)\n",
    "\n",
    "def data_to_recommended_and_selected(dataframe: pd.DataFrame, user_col: str = 'UserID', interactions_col: str = 'Impressions'):\n",
    "    data = list()\n",
    "    items = set()\n",
    "    for user, user_interactions in zip(dataframe[user_col].values, dataframe[interactions_col].values):\n",
    "        \n",
    "        # Interações são da forma noticia_id-clicado, exemplo: N23699-0 N21291-0 N1901-1 N27292-0 N17443-0\n",
    "\n",
    "        R = [interaction.split('-')[0] for interaction in user_interactions.split()] \n",
    "        S = [interaction.split('-')[0] for interaction in user_interactions.split() if interaction[-1] == '1']\n",
    "        \n",
    "        items.update(R)\n",
    "\n",
    "        data.append((user, ' '.join(R), ' '.join(S)))\n",
    "\n",
    "    return pd.DataFrame(data, columns=['UserID', 'R', 'S']), items\n",
    "\n",
    "train_data, train_items = data_to_recommended_and_selected(train_data)\n",
    "valid_data, valid_items = data_to_recommended_and_selected(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['R'].apply(lambda x: len(x.split(' '))).plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUbUlEQVR4nO3df7BfdX3n8edLovKjrfxKs5jQhtasllpRiECX1bWkIj8sYbvV4lTNMozpTNOK3c5UcHY2XS0zMNOKsrNlS4U2WAURtWQXKkZEu/1DIPxY+SVLlp+JQFKDBKUFg+/94/u5eIkJ+d6T+/2ee7nPx8x3vud8zuec8/7eyc3rns/58U1VIUlSFy/ruwBJ0uxliEiSOjNEJEmdGSKSpM4MEUlSZ/P6LmDcDj744Fq8eHHfZUjSrHHLLbf8U1XN39myORciixcvZv369X2XIUmzRpKHdrXM4SxJUmeGiCSpM0NEktSZISJJ6swQkSR1NrIQSXJpks1J7pzUdmCSdUnua+8HtPYkuTDJhiTfSnLkpHVWtP73JVkxqf2oJHe0dS5MklF9FknSzo3ySORvgBN3aDsbuL6qlgDXt3mAk4Al7bUSuAgGoQOsBo4BjgZWTwRP6/OBSevtuC9J0oiNLESq6h+ArTs0LwfWtOk1wGmT2i+rgW8C+yc5BHgHsK6qtlbVE8A64MS27Geq6ps1eJb9ZZO2JUkak3GfE1lQVY+26ceABW16IfDIpH4bW9uLtW/cSftOJVmZZH2S9Vu2bNmzTyBJel5vd6xXVSUZyzdiVdXFwMUAS5cu7bzPxWdfM201TcWD553Sy34laXfGfSTyeBuKor1vbu2bgEMn9VvU2l6sfdFO2iVJYzTuEFkLTFxhtQK4elL7+9tVWscCT7Zhr+uAE5Ic0E6onwBc15ZtS3Jsuyrr/ZO2JUkak5ENZyW5HHgbcHCSjQyusjoPuDLJmcBDwLtb92uBk4ENwNPAGQBVtTXJx4CbW7+PVtXEyfrfY3AF2D7A37eXJGmMRhYiVfWeXSxatpO+BazaxXYuBS7dSft64PV7UqMkac94x7okqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnvYRIkj9McleSO5NcnmTvJIcluTHJhiSfS/KK1veVbX5DW7540nbOae33JnlHH59FkuaysYdIkoXAB4GlVfV6YC/gdOB84IKqeg3wBHBmW+VM4InWfkHrR5LD23q/DJwI/EWSvcb5WSRprutrOGsesE+SecC+wKPA8cBVbfka4LQ2vbzN05YvS5LWfkVVPVNVDwAbgKPHU74kCXoIkaraBPwZ8DCD8HgSuAX4XlVtb902Agvb9ELgkbbu9tb/oMntO1lHkjQGfQxnHcDgKOIw4NXAfgyGo0a5z5VJ1idZv2XLllHuSpLmlD6Gs34deKCqtlTVD4EvAscB+7fhLYBFwKY2vQk4FKAtfxXw3cntO1nnBarq4qpaWlVL58+fP92fR5LmrD5C5GHg2CT7tnMby4C7gRuA32p9VgBXt+m1bZ62/GtVVa399Hb11mHAEuCmMX0GSRKDE9xjVVU3JrkKuBXYDtwGXAxcA1yR5E9b2yVtlUuATyfZAGxlcEUWVXVXkisZBNB2YFVVPTfWDyNJc9zYQwSgqlYDq3dovp+dXF1VVf8CvGsX2zkXOHfaC5QkDcU71iVJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTO5vVdgGa2xWdf08t+HzzvlF72K2lqPBKRJHVmiEiSOhsqRJL8yqgLkSTNPsMeifxFkpuS/F6SV420IknSrDFUiFTVW4DfAQ4Fbkny2SRvH2llkqQZb+hzIlV1H/CfgQ8D/w64MMm3k/zmqIqTJM1sw54TeUOSC4B7gOOB36iqX2rTF0x1p0n2T3JVC6F7kvxqkgOTrEtyX3s/oPVNkguTbEjyrSRHTtrOitb/viQrplqHJGnPDHsk8t+AW4EjqmpVVd0KUFXfYXB0MlWfBL5cVa8DjmAQTmcD11fVEuD6Ng9wErCkvVYCFwEkORBYDRwDHA2snggeSdJ4DHuz4SnAP1fVcwBJXgbsXVVPV9Wnp7LDdmL+rcB/BKiqZ4FnkywH3ta6rQG+zmDobDlwWVUV8M12FHNI67uuqra27a4DTgQun0o90lzX1w2l4E2lLwXDHol8Fdhn0vy+ra2Lw4AtwF8nuS3Jp5LsByyoqkdbn8eABW16IfDIpPU3trZdtf+EJCuTrE+yfsuWLR3LliTtaNgQ2buqvj8x06b37bjPecCRwEVV9SbgB/x46Gpi+wVUx+3/hKq6uKqWVtXS+fPnT9dmJWnOGzZEfrDDCe2jgH/uuM+NwMaqurHNX8UgVB5vw1S0981t+SYGlxZPWNTadtUuSRqTYUPkQ8Dnk/zvJP8IfA74/S47rKrHgEeSvLY1LQPuBtYCE1dYrQCubtNrgfe3q7SOBZ5sw17XASckOaCdUD+htUmSxmSoE+tVdXOS1wET//HfW1U/3IP9/gHwmSSvAO4HzmAQaFcmORN4CHh363stcDKwAXi69aWqtib5GHBz6/fRiZPskqTxmMqj4N8MLG7rHJmEqrqsy06r6nZg6U4WLdtJ3wJW7WI7lwKXdqlBkrTnhgqRJJ8GfhG4HXiuNRfQKUQkSS8Nwx6JLAUOb0cFkiQBw59YvxP4V6MsRJI0+wx7JHIwcHeSm4BnJhqr6tSRVCVJmhWGDZE/GWURkqTZadhLfL+R5OeBJVX11ST7AnuNtjRJ0kw37KPgP8DgzvK/bE0Lgb8bUU2SpFli2BPrq4DjgG3w/BdU/eyoipIkzQ7Dhsgz7ZHtACSZxzQ+IFGSNDsNGyLfSPIRYJ/23eqfB/7n6MqSJM0Gw4bI2Qy+A+QO4HcZPM+qyzcaSpJeQoa9OutHwF+1lyRJwPDPznqAnZwDqapfmPaKJEmzxlSenTVhb+BdwIHTX44kaTYZ6pxIVX130mtTVX0COGW0pUmSZrphh7OOnDT7MgZHJlP5LhJJ0kvQsEHw55OmtwMP8uNvHpQkzVHDXp31a6MuRJI0+ww7nPWfXmx5VX18esqRJM0mU7k6683A2jb/G8BNwH2jKEqSNDsMGyKLgCOr6imAJH8CXFNV7x1VYZKkmW/Yx54sAJ6dNP9sa5MkzWHDHolcBtyU5Ett/jRgzUgqkiTNGsNenXVukr8H3tKazqiq20ZXliRpNhh2OAtgX2BbVX0S2JjksBHVJEmaJYb9etzVwIeBc1rTy4G/HVVRkqTZYdgjkX8PnAr8AKCqvgP89KiKkiTNDsOGyLNVVbTHwSfZb3QlSZJmi2FD5Mokfwnsn+QDwFfxC6okac7b7dVZSQJ8DngdsA14LfBfqmrdiGuTJM1wuw2Rqqok11bVrwAGhyTpecMOZ92a5M0jrUSSNOsMe8f6McB7kzzI4AqtMDhIecOoCpMkzXwvGiJJfq6qHgbeMd07TrIXsB7YVFXvbDcvXgEcBNwCvK+qnk3ySgaPXTkK+C7w21X1YNvGOcCZwHPAB6vquumuU5K0a7s7Evk7Bk/vfSjJF6rqP0zjvs8C7gF+ps2fD1xQVVck+R8MwuGi9v5EVb0myemt328nORw4Hfhl4NXAV5P866p6bhprlKRptfjsa3rZ74PnnTKS7e7unEgmTf/CdO00ySLgFOBTbT7A8cBVrcsaBg95BFjOjx/2eBWwrPVfDlxRVc9U1QPABuDo6apRkrR7uwuR2sX0nvoE8MfAj9r8QcD3qmp7m98ILGzTC4FHANryJ1v/59t3ss4LJFmZZH2S9Vu2bJnGjyFJc9vuQuSIJNuSPAW8oU1vS/JUkm1ddpjkncDmqrqly/pdVNXFVbW0qpbOnz9/XLuVpJe8Fz0nUlV7jWCfxwGnJjkZ2JvBOZFPMrgbfl472lgEbGr9NwGHMnhy8DzgVQxOsE+0T5i8jiRpDKbyKPhpUVXnVNWiqlrM4MT416rqd4AbgN9q3VYAV7fptW2etvxr7Tlea4HTk7yyXdm1hMH3vkuSxmTY+0TG4cPAFUn+FLgNuKS1XwJ8OskGYCuD4KGq7kpyJXA3sB1Y5ZVZkjRevYZIVX0d+Hqbvp+dXF1VVf8CvGsX658LnDu6CiVJL2bsw1mSpJcOQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM5m0s2G2oW+Hh0tSbvjkYgkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJn3mwozRDeVKrZyCMRSVJnhogkqTNDRJLUmedENCP1eX7gwfNO6W3fGg/PP00fj0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkznzsiaTe+PiR2W/sRyJJDk1yQ5K7k9yV5KzWfmCSdUnua+8HtPYkuTDJhiTfSnLkpG2taP3vS7Ji3J9Fkua6PoaztgN/VFWHA8cCq5IcDpwNXF9VS4Dr2zzAScCS9loJXASD0AFWA8cARwOrJ4JHkjQeYw+Rqnq0qm5t008B9wALgeXAmtZtDXBam14OXFYD3wT2T3II8A5gXVVtraongHXAieP7JJKkXk+sJ1kMvAm4EVhQVY+2RY8BC9r0QuCRSattbG27at/ZflYmWZ9k/ZYtW6bvA0jSHNdbiCT5KeALwIeqatvkZVVVQE3Xvqrq4qpaWlVL58+fP12blaQ5r5cQSfJyBgHymar6Ymt+vA1T0d43t/ZNwKGTVl/U2nbVLkkakz6uzgpwCXBPVX180qK1wMQVViuAqye1v79dpXUs8GQb9roOOCHJAe2E+gmtTZI0Jn3cJ3Ic8D7gjiS3t7aPAOcBVyY5E3gIeHdbdi1wMrABeBo4A6Cqtib5GHBz6/fRqto6lk8gSQJ6CJGq+kcgu1i8bCf9C1i1i21dClw6fdVJkqbCx55IkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjqb9SGS5MQk9ybZkOTsvuuRpLlkVodIkr2A/w6cBBwOvCfJ4f1WJUlzx6wOEeBoYENV3V9VzwJXAMt7rkmS5ox5fRewhxYCj0ya3wgcs2OnJCuBlW32+0nu7bi/g4F/6rjuKFnX1LxoXTl/jJW80Kz8efXIuqYg5+9RXT+/qwWzPUSGUlUXAxfv6XaSrK+qpdNQ0rSyrqmxrqmxrqmZa3XN9uGsTcChk+YXtTZJ0hjM9hC5GViS5LAkrwBOB9b2XJMkzRmzejirqrYn+X3gOmAv4NKqumuEu9zjIbERsa6psa6psa6pmVN1papGsV1J0hww24ezJEk9MkQkSZ0ZIruR5NAkNyS5O8ldSc7quyaAJHsnuSnJ/2l1/de+a5osyV5Jbkvyv/quZbIkDya5I8ntSdb3Xc+EJPsnuSrJt5Pck+RXZ0BNr20/p4nXtiQf6rsugCR/2P7d35nk8iR7910TQJKzWk139fmzSnJpks1J7pzUdmCSdUnua+8HTMe+DJHd2w78UVUdDhwLrJohj1Z5Bji+qo4A3gicmOTYfkt6gbOAe/ouYhd+rareOMOu5f8k8OWqeh1wBDPgZ1dV97af0xuBo4CngS/1WxUkWQh8EFhaVa9ncFHN6f1WBUleD3yAwZM0jgDemeQ1PZXzN8CJO7SdDVxfVUuA69v8HjNEdqOqHq2qW9v0Uwx+uRf2WxXUwPfb7Mvba0ZcJZFkEXAK8Km+a5kNkrwKeCtwCUBVPVtV3+u1qJ+0DPh/VfVQ34U084B9kswD9gW+03M9AL8E3FhVT1fVduAbwG/2UUhV/QOwdYfm5cCaNr0GOG069mWITEGSxcCbgBt7LgV4fsjodmAzsK6qZkRdwCeAPwZ+1HMdO1PAV5Lc0h6HMxMcBmwB/roNAX4qyX59F7WD04HL+y4CoKo2AX8GPAw8CjxZVV/ptyoA7gTekuSgJPsCJ/PCm6H7tqCqHm3TjwELpmOjhsiQkvwU8AXgQ1W1re96AKrquTbUsAg4uh1O9yrJO4HNVXVL37Xswr+tqiMZPPl5VZK39l0Qg7+qjwQuqqo3AT9gmoYapkO7kfdU4PN91wLQxvKXMwjfVwP7JXlvv1VBVd0DnA98BfgycDvwXJ817UoN7u2YlpELQ2QISV7OIEA+U1Vf7LueHbWhjxv4yTHQPhwHnJrkQQZPVT4+yd/2W9KPtb9iqarNDMb3j+63ImDw4NCNk44kr2IQKjPFScCtVfV434U0vw48UFVbquqHwBeBf9NzTQBU1SVVdVRVvRV4Avi/fdc0yeNJDgFo75unY6OGyG4kCYOx6nuq6uN91zMhyfwk+7fpfYC3A9/utSigqs6pqkVVtZjBEMjXqqr3vxIBkuyX5KcnpoETGAxB9KqqHgMeSfLa1rQMuLvHknb0HmbIUFbzMHBskn3b7+cyZsCFCABJfra9/xyD8yGf7beiF1gLrGjTK4Crp2Ojs/qxJ2NyHPA+4I52/gHgI1V1bX8lAXAIsKZ9MdfLgCurakZdTjsDLQC+NPh/h3nAZ6vqy/2W9Lw/AD7Tho7uB87ouR7g+bB9O/C7fdcyoapuTHIVcCuDqydvY+Y8auQLSQ4Cfgis6usCiSSXA28DDk6yEVgNnAdcmeRM4CHg3dOyLx97IknqyuEsSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ39f7uXvMYaKZTFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst_s = train_data['R'].apply(lambda x: len(x.split(' ')))\n",
    "tst_s[tst_s <= 10].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['S'].apply(lambda x: len(x.split(' '))).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    149116.000000\n",
       "mean          1.506827\n",
       "std           1.153562\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          35.000000\n",
       "Name: S, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['S'].apply(lambda x: len(x.split(' '))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nka72RoX8w2Z"
   },
   "source": [
    "# $P_S$\n",
    "- Criar o modelo pytorch\n",
    "- Entender como computar a função de perda e treinar\n",
    "\n",
    "Talvez usar máscara para dizer quais elementos estão em R e S.\n",
    "\n",
    "Camada de embedding:\n",
    "- Transformar itens e usuários em indices inteiros.\n",
    "\n",
    "\n",
    "Loss:\n",
    "- Entrada: \n",
    "    - batch com saídas da rede\n",
    "    - Mascara target => indica quais elementos de K estão na mascara.\n",
    "- Reduce => media => é a nivel de batch\n",
    "- Produto interno saída x mascara e soma.\n",
    "\n",
    "\n",
    "Possíveis jeitos de passar as entradas:\n",
    "- 1:\n",
    "    - X: NxK: \n",
    "    - y: NxK: mascara. 1 se item foi escolhido e 0 cc.\n",
    "- 2:\n",
    "    - Dataset cospe dicionarios {u, r, s} ou tuplas (u, r, s)\n",
    "    - collate_fn junta essas entradas em um tensor com padding.\n",
    "\n",
    "\n",
    "Tomar cuidado para não maximizar uma função que é de minimizar ou o contrário.\n",
    "\n",
    "\n",
    "Checar tamanho de K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4B2wBzkT-IOn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeba/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "_GSuBtEHIZBP"
   },
   "outputs": [],
   "source": [
    "def gen_code_dict(code_l):\n",
    "    #gen_code_dict(list(df['UserID'].unique()))\n",
    "    #gen_code_dict(\" \".join(df['R']).split(\" \"))\n",
    "    code_d = {}\n",
    "    i = 1 # 0 eh PADDING\n",
    "    for code in set(code_l):\n",
    "        code_d[code] = i\n",
    "        i += 1\n",
    "    return code_d\n",
    "    \n",
    "class MIND_dataset(Dataset):\n",
    "    def get_picked_inds(self, r, s):\n",
    "        ind_l = []\n",
    "        for picked_i in s:\n",
    "            for ind, i in enumerate(r):\n",
    "                if i == picked_i:\n",
    "                    ind_l.append(ind)\n",
    "                    break\n",
    "        return ind_l\n",
    "\n",
    "\n",
    "    def __init__(self, df, user_d, item_d):\n",
    "        \"\"\"\n",
    "        Recebe um DataFrame com as colunas ['UserID', 'R', 'S']\n",
    "        UserID: ids de usuario\n",
    "        R: listas de ids de itens recomendados a U\n",
    "        S: listas de ids de itens de R escolhidos por U\n",
    "        \n",
    "        user_d: dicionario que mapeia de id de usuário para numero inteiro, sendo que 0 é PAD\n",
    "        item_d: dicionario que mapeia de id de item para numero inteiro, sendo que 0 é PAD\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Transformar os codigos de item e usuario em indices inteiros. 0 eh PADDING\n",
    "        self.user_d = user_d\n",
    "        self.item_d = item_d\n",
    "\n",
    "        self.df = pd.DataFrame(index=df.index)\n",
    "        self.df['U'] = df['UserID'].apply(lambda x: self.user_d[x])\n",
    "        self.df['R'] = df['R'].apply(lambda x: [self.item_d[i] for i in x.split(' ')])\n",
    "        # S\n",
    "        self.df['S_picked'] = df['S'].apply(lambda x: [self.item_d[i] for i in x.split(' ')])\n",
    "        self.df['S'] = self.df.apply(lambda x: self.get_picked_inds(x['R'], x['S_picked']), axis=1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Retorna uma tupla com U, R e S\n",
    "        U => id do usuário\n",
    "        R => lista de ids de itens\n",
    "        S => lista de indices de R indicando quais itens foram escolhidos.\n",
    "        '''\n",
    "        return self.df['U'].iloc[idx], self.df['R'].iloc[idx], self.df['S'].iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_n_users(self):\n",
    "        return len(self.user_d)+1\n",
    "\n",
    "    def get_n_items(self):\n",
    "        return len(self.item_d)+1\n",
    "\n",
    "def mind_collate_fn(data):\n",
    "    '''\n",
    "    Retorna tupla: u, r, r_mask, s\n",
    "    '''\n",
    "    batch_sz = len(data)\n",
    "    max_len = max([len(r) for _,r,_ in data])\n",
    "\n",
    "    u_batch = torch.zeros(batch_sz, 1, dtype=torch.long)\n",
    "    r_batch = torch.zeros(batch_sz, max_len, dtype=torch.long)\n",
    "    r_mask_batch = torch.zeros(batch_sz, max_len, dtype=torch.long)\n",
    "    s_batch = torch.zeros(batch_sz, max_len, dtype=torch.long)\n",
    "\n",
    "    for i, (u,r,s) in enumerate(data):\n",
    "        u_batch[i] = u\n",
    "        r_batch[i] = torch.LongTensor(r + [0]*(max_len-len(r)))\n",
    "        r_mask_batch[i] = torch.LongTensor([1]*len(r) + [0]*(max_len-len(r)))\n",
    "        s_batch[i] = torch.LongTensor([(1 if ind in s else 0) for ind in range(max_len)])\n",
    "    return u_batch, r_batch, r_mask_batch, s_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class MIND_P_R_Dataset(Dataset):\n",
    "    def __init__(self, mind_ds, max_sampling_len):\n",
    "        \"\"\"\n",
    "        Retorna amostras com negative sampling.\n",
    "        mind_ds: MIND_Dataset\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mind_ds = mind_ds\n",
    "        self.item_set = set(mind_ds.item_d.values())\n",
    "        self.max_sampling_len = max_sampling_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Retorna uma tupla com U, R_pos, R_neg\n",
    "        U => id do usuário\n",
    "        R_pos => lista de ids de itens em r para U amostrados\n",
    "        R_neg => lista de ids de itens não em r para U amostrados\n",
    "        '''\n",
    "        u,r,_ = self.mind_ds[idx]\n",
    "        pos_r = random.sample(r, min(self.max_sampling_len, len(r)))\n",
    "        neg_r = random.sample(self.item_set - set(r), len(pos_r))\n",
    "        return u, pos_r, neg_r\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mind_ds)\n",
    "    \n",
    "def mind_p_r_collate_fn(data):\n",
    "    '''\n",
    "    Retorna tupla: u, pos_r, pos_r_mask, neg_r, neg_r_mask\n",
    "    '''\n",
    "    batch_sz = len(data)\n",
    "    pos_max_len = max([len(pos_r) for _,pos_r,_ in data])\n",
    "    neg_max_len = max([len(neg_r) for _,_,neg_r in data])\n",
    "\n",
    "    u_batch = torch.zeros(batch_sz, 1, dtype=torch.long)\n",
    "    pos_r_batch = torch.zeros(batch_sz, pos_max_len, dtype=torch.long)\n",
    "    pos_r_mask_batch = torch.zeros(batch_sz, pos_max_len, dtype=torch.long)\n",
    "    neg_r_batch = torch.zeros(batch_sz, neg_max_len, dtype=torch.long)\n",
    "    neg_r_mask_batch = torch.zeros(batch_sz, neg_max_len, dtype=torch.long)\n",
    "\n",
    "    for i, (u, pos_r, neg_r) in enumerate(data):\n",
    "        u_batch[i] = u\n",
    "        pos_r_batch[i] = torch.LongTensor(pos_r + [0]*(pos_max_len-len(pos_r)))\n",
    "        pos_r_mask_batch[i] = torch.LongTensor([1]*len(pos_r) + [0]*(pos_max_len-len(pos_r)))\n",
    "        neg_r_batch[i] = torch.LongTensor(neg_r + [0]*(neg_max_len-len(neg_r)))\n",
    "        neg_r_mask_batch[i] = torch.LongTensor([1]*len(neg_r) + [0]*(neg_max_len-len(neg_r)))\n",
    "        \n",
    "    return u_batch, pos_r_batch, pos_r_mask_batch, neg_r_batch, neg_r_mask_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "BwatALeiYNHR"
   },
   "outputs": [],
   "source": [
    "class P_S_Network(nn.Module):\n",
    "    def __init__(self, n_users, n_itens, K, emb_dim=32):\n",
    "        super(P_S_Network, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim, padding_idx=0)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=n_itens, embedding_dim=emb_dim, padding_idx=0)\n",
    "        self.w = nn.Parameter(torch.randn(1, K))\n",
    "        self.K = K\n",
    "        \n",
    "    def forward(self, u, r, r_mask, s, beta):\n",
    "        \"\"\"\n",
    "        Entrada:\n",
    "            u: Indice do usuário\n",
    "                torch.LongTensor(batch_sz, 1)\n",
    "            r: Tensor de indices dos itens recomendados ao usuário\n",
    "                torch.LongTensor(batch_sz, max_len)\n",
    "            r_mask: Máscara binária indicando quais elementos de r não são padding\n",
    "                torch.LongTensor(batch_sz, max_len)\n",
    "            s: Máscara binária indicando quais elementos de r estão em s.\n",
    "                torch.LongTensor(batch_sz, max_len)\n",
    "            beta: Variavel exogena correspondente aos itens em r\n",
    "                torch.tensor(batch_sz, max_len)\n",
    "        \"\"\"\n",
    "        max_len = r.size(1)\n",
    "        w_mul = beta * (self.w[:,:max_len])\n",
    "\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(r)\n",
    "        emb_sim = torch.bmm(u_e, i_e.permute(0,2,1)).squeeze()\n",
    "\n",
    "        return (w_mul + emb_sim) * r_mask\n",
    "\n",
    "def p_s_loss(out, s):\n",
    "    # Loss to be minimized\n",
    "    out_soft = F.log_softmax(out, dim=1)\n",
    "    return -(out_soft*s).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_R_Network(nn.Module):\n",
    "    def __init__(self, n_users, n_itens, emb_dim=32):\n",
    "        super(P_R_Network, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim, padding_idx=0)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=n_itens, embedding_dim=emb_dim, padding_idx=0)\n",
    "        self.w = nn.Parameter(torch.randn(1, n_itens))\n",
    "        \n",
    "    def forward(self, u, r, r_mask, alpha):\n",
    "        \"\"\"\n",
    "        Entrada:\n",
    "            u: Indice do usuário\n",
    "                torch.LongTensor(batch_sz, 1)\n",
    "            r: Tensor de indices dos itens recomendados ao usuário\n",
    "                torch.LongTensor(batch_sz, max_len)\n",
    "            r_mask: Máscara binária indicando quais elementos de r não são padding\n",
    "                torch.LongTensor(batch_sz, max_len)\n",
    "            alpha: Variavel exogena correspondente aos itens em r\n",
    "                torch.tensor(batch_sz, max_len)\n",
    "        \"\"\"\n",
    "        # Seleciona os w correspondentes aos itens em r\n",
    "        w_mul = alpha * (self.w[0,r])\n",
    "\n",
    "        u_e = self.user_emb(u)\n",
    "        i_e = self.item_emb(r)\n",
    "        emb_sim = torch.bmm(u_e, i_e.permute(0,2,1)).squeeze()\n",
    "\n",
    "        return (w_mul + emb_sim) * r_mask\n",
    "\n",
    "def p_r_loss(pos_scores, neg_scores):\n",
    "    \"\"\"\n",
    "    Negative sampling loss.\n",
    "    Entrada:\n",
    "        pos_scores: torch.tensor(batch_sz, pos_max_len)\n",
    "        neg_scores: torch.tensor(batch_sz, neg_max_len)\n",
    "    \"\"\"\n",
    "    # Loss to be minimized\n",
    "    eps=1e-7\n",
    "    pos_soft = F.logsigmoid(pos_scores).sum()\n",
    "    neg_soft = torch.log(eps + 1 - torch.sigmoid(neg_scores)).sum()\n",
    "    return -(pos_soft + neg_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "RAvnmUFWvIRA"
   },
   "outputs": [],
   "source": [
    "def ps_train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (u, r, r_mask, s) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        batch_sz = u.size(0)\n",
    "        max_len = r.size(1)\n",
    "        beta = torch.randn(batch_sz, max_len)\n",
    "        out = model(u, r, r_mask, s, beta)\n",
    "        loss = loss_fn(out, s)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % (len(dataloader)//10) == 0:\n",
    "            loss, current = loss.item() / batch_sz, batch * len(u)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def ps_test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u, r, r_mask, s in dataloader:\n",
    "            batch_sz = u.size(0)\n",
    "            max_len = r.size(1)\n",
    "            beta = torch.randn(batch_sz, max_len)\n",
    "            out = model(u, r, r_mask, s, beta)\n",
    "            test_loss += loss_fn(out, s).item() / batch_sz\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (u, pos_r, pos_r_mask, neg_r, neg_r_mask) in enumerate(dataloader):\n",
    "        batch_sz = u.size(0)\n",
    "        pos_max_len = pos_r.size(1)\n",
    "        neg_max_len = neg_r.size(1)\n",
    "        \n",
    "        pos_alpha = torch.randn(batch_sz, pos_max_len)\n",
    "        pos_scores = model(u, pos_r, pos_r_mask, pos_alpha)\n",
    "        \n",
    "        neg_alpha = torch.randn(batch_sz, neg_max_len)\n",
    "        neg_scores = model(u, neg_r, neg_r_mask, neg_alpha)\n",
    "        \n",
    "        loss = loss_fn(pos_scores, neg_scores)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % (len(dataloader)//10) == 0:\n",
    "            loss, current = loss.item() / batch_sz, batch * len(u)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def pr_test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u, pos_r, pos_r_mask, neg_r, neg_r_mask in dataloader:\n",
    "            batch_sz = u.size(0)\n",
    "            pos_max_len = pos_r.size(1)\n",
    "            neg_max_len = neg_r.size(1)\n",
    "        \n",
    "            pos_alpha = torch.randn(batch_sz, pos_max_len)\n",
    "            pos_scores = model(u, pos_r, pos_r_mask, pos_alpha)\n",
    "        \n",
    "            neg_alpha = torch.randn(batch_sz, neg_max_len)\n",
    "            neg_scores = model(u, neg_r, neg_r_mask, neg_alpha)\n",
    "            \n",
    "            test_loss += loss_fn(pos_scores, neg_scores).item() / batch_sz\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino :  134204\n",
      "Val :  12799\n"
     ]
    }
   ],
   "source": [
    "# Pre-processamento\n",
    "df_ids = list(range(len(train_data)))\n",
    "random.shuffle(df_ids)\n",
    "train_ids = df_ids[:int(len(train_data)*0.9)]\n",
    "val_ids = df_ids[int(len(train_data)*0.9):]\n",
    "\n",
    "train_df = train_data.iloc[train_ids]\n",
    "val_df = train_data.iloc[val_ids]\n",
    "\n",
    "user_d = gen_code_dict(list(train_df['UserID'].unique()))\n",
    "item_d = gen_code_dict(\" \".join(train_df['R']).split(\" \"))\n",
    "\n",
    "item_check_s = val_df.apply(lambda x: x['R'].split() + x['S'].split(), axis=1).apply(lambda l: all([ i in item_d for i in l]))\n",
    "user_check_s = val_df['UserID'].apply(lambda x: x in user_d)\n",
    "val_df = val_df[item_check_s & user_check_s]\n",
    "print('Treino : ', len(train_df))\n",
    "print('Val : ', len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "batch_size = 32\n",
    "p_r_max_sampling_len = 5\n",
    "\n",
    "ps_train_ds = MIND_dataset(train_df, user_d, item_d)\n",
    "ps_train_dl = DataLoader(ps_train_ds, batch_size=batch_size, shuffle=True, collate_fn=mind_collate_fn)\n",
    "\n",
    "ps_val_ds = MIND_dataset(val_df, user_d, item_d)\n",
    "ps_val_dl = DataLoader(ps_val_ds, batch_size=batch_size, shuffle=True, collate_fn=mind_collate_fn)\n",
    "\n",
    "\n",
    "pr_train_ds = MIND_P_R_Dataset(ps_train_ds, p_r_max_sampling_len)\n",
    "pr_train_dl = DataLoader(pr_train_ds, batch_size=batch_size, shuffle=True, collate_fn=mind_p_r_collate_fn)\n",
    "\n",
    "pr_val_ds = MIND_P_R_Dataset(ps_val_ds, p_r_max_sampling_len)\n",
    "pr_val_dl = DataLoader(pr_val_ds, batch_size=batch_size, shuffle=True, collate_fn=mind_p_r_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_R:\n",
      "w torch.Size([1, 19762])\n",
      "user_emb.weight torch.Size([47372, 32])\n",
      "item_emb.weight torch.Size([19762, 32])\n"
     ]
    }
   ],
   "source": [
    "pr_model = P_R_Network(len(user_d)+1, len(item_d)+1)\n",
    "print('P_R:')     \n",
    "for name, param in pr_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_save_path = 'pr_model.pth'\n",
    "learning_rate = 1e-3\n",
    "epochs = 2\n",
    "optimizer = torch.optim.SGD(pr_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 20.892809  [    0/134204]\n",
      "loss: 23.165180  [13408/134204]\n",
      "loss: 24.427330  [26816/134204]\n",
      "loss: 24.650696  [40224/134204]\n",
      "loss: 17.675331  [53632/134204]\n",
      "loss: 21.077366  [67040/134204]\n",
      "loss: 23.806715  [80448/134204]\n",
      "loss: 21.420200  [93856/134204]\n",
      "loss: 22.868141  [107264/134204]\n",
      "loss: 20.493774  [120672/134204]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2y/kyv2hdc1433f67fbbd7zm9zr0000gn/T/ipykernel_44627/3999798882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch_n+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpr_train_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_train_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_r_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpr_test_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_val_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_r_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch_n\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2y/kyv2hdc1433f67fbbd7zm9zr0000gn/T/ipykernel_44627/1704881875.py\u001b[0m in \u001b[0;36mpr_train_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_n in range(epochs):\n",
    "    print(f\"Epoch {epoch_n+1}\\n-------------------------------\")\n",
    "    pr_train_loop(pr_train_dl, pr_model, p_r_loss, optimizer)\n",
    "    pr_test_loop(pr_val_dl, pr_model, p_r_loss)\n",
    "    if epoch_n % 3 == 0:\n",
    "        torch.save(pr_model.state_dict(), pr_save_path)\n",
    "torch.save(pr_model.state_dict(), pr_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pr_model = P_R_Network(len(user_d)+1, len(item_d)+1)\n",
    "loaded_pr_model.load_state_dict(torch.load(pr_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P_S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_S:\n",
      "w torch.Size([1, 299])\n",
      "user_emb.weight torch.Size([47372, 32])\n",
      "item_emb.weight torch.Size([19762, 32])\n"
     ]
    }
   ],
   "source": [
    "ps_model = P_S_Network(len(user_d)+1, len(item_d)+1, 299)\n",
    "# Parametros\n",
    "print('P_S:')\n",
    "for name, param in ps_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_save_path = 'ps_model.pth'\n",
    "learning_rate = 1e-3\n",
    "epochs = 2\n",
    "optimizer = torch.optim.SGD(ps_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 17.472754  [    0/134204]\n",
      "loss: 14.336349  [13408/134204]\n",
      "loss: 15.767492  [26816/134204]\n",
      "loss: 16.902426  [40224/134204]\n",
      "loss: 21.651711  [53632/134204]\n",
      "loss: 15.627363  [67040/134204]\n",
      "loss: 17.674099  [80448/134204]\n",
      "loss: 15.149418  [93856/134204]\n",
      "loss: 17.354435  [107264/134204]\n",
      "loss: 15.267361  [120672/134204]\n",
      "loss: 15.158476  [134080/134204]\n",
      "Test Error: Avg loss: 16.938951 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 16.431202  [    0/134204]\n",
      "loss: 12.835434  [13408/134204]\n",
      "loss: 11.642828  [26816/134204]\n",
      "loss: 16.493567  [40224/134204]\n",
      "loss: 16.286417  [53632/134204]\n",
      "loss: 16.674128  [67040/134204]\n",
      "loss: 9.886863  [80448/134204]\n",
      "loss: 21.087910  [93856/134204]\n",
      "loss: 12.529696  [107264/134204]\n",
      "loss: 13.817736  [120672/134204]\n",
      "loss: 11.889943  [134080/134204]\n",
      "Test Error: Avg loss: 16.078595 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_n in range(epochs):\n",
    "    print(f\"Epoch {epoch_n+1}\\n-------------------------------\")\n",
    "    ps_train_loop(ps_train_dl, ps_model, p_s_loss, optimizer)\n",
    "    ps_test_loop(ps_val_dl, ps_model, p_s_loss)\n",
    "    if epoch_n % 3 == 0:\n",
    "        torch.save(ps_model.state_dict(), ps_save_path)\n",
    "torch.save(ps_model.state_dict(), ps_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_ps_model = P_S_Network(len(user_d)+1, len(item_d)+1, 299)\n",
    "loaded_ps_model.load_state_dict(torch.load(ps_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A FAZER\n",
    "\n",
    "Pegar o dataset MIND SMALL\n",
    "\n",
    "- Checar se as listas de impressao sao geralmente escolhidas do inicio\n",
    "- Modificar modelo P_S.forward para receber beta como entrada. Ou criar um outro forward que pode ser usado com beta.\n",
    "- Documentar rapidamente as entradas e saidas. E checar a classe Dataset.\n",
    "- Implementar P_R\n",
    "    - Ter um método que recebe tau, para a política gaussiana\n",
    "- Treinar\n",
    "\n",
    "\n",
    "Reduzir o tamanho das imp_logs, opções:\n",
    "- Retirar todas que maiores que 5.\n",
    "- Truncar as listas em tamanho 5, retirando as que não possuem S nos 5 primeiros\n",
    "- Pegar os itens escolhidos e selecionar aleatoriamente mais outros para inteirar 5. Aleatorizar a ordem.\n",
    "- Dividir a lista em menores, o que pode significar reutilizar o S várias vezes.\n",
    "\n",
    "The negative samples are selected from the whole item set or the impression list. When optimizing 𝑝𝑹 and 𝑝𝑺 , we empirically set the learning rate as 0.001, and the user/item embedding sizes are both tunned in {16, 32, 64, 128, 256, 512}. The length of the impression list (i.e., |𝑹|) is set as 5, and the size of 𝑺 (i.e., 𝑘) is determined in {1, 2, 3}. The Gaussian policy is implemented as a two-layers fully- connected neural network, where the hidden dimension is searched in {16, 32, 64}.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
